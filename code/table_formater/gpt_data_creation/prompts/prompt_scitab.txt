Task Description: Given the following table and question, format the table into a python array.
------
'''
Caption: A bag-of-concepts model improves relation extraction in a narrow knowledge domain with limited data Table 1: Performance of supervised learning models with different features.
Table:
|| Feature | LR P | LR R | LR F1 | SVM P | SVM R | SVM F1 | ANN P | ANN R | ANN F1 ||
|| +BoW | 0.93 | 0.91 | 0.92 | 0.94 | 0.92 | 0.93 | 0.91 | 0.91 | 0.91 ||
|| +BoC (Wiki-PubMed-PMC) | 0.94 | 0.92 | 0.93 | 0.94 | 0.92 | 0.93 | 0.91 | 0.91 | 0.91 ||
|| +BoC (GloVe) | 0.93 | 0.92 | 0.92 | 0.94 | 0.92 | 0.93 | 0.91 | 0.91 | 0.91 ||
|| +ASM | 0.90 | 0.85 | 0.88 | 0.90 | 0.86 | 0.88 | 0.89 | 0.89 | 0.89 ||
|| +Sentence Embeddings(SEs) | 0.89 | 0.89 | 0.89 | 0.90 | 0.86 | 0.88 | 0.88 | 0.88 | 0.88 ||
|| +BoC(Wiki-PubMed-PMC)+SEs | 0.92 | 0.92 | 0.92 | 0.94 | 0.92 | 0.93 | 0.91 | 0.91 | 0.91 ||

Question: Is it true that The models using BoC outperform models using BoW as well as ASM features?
'''

table_data = [["Feature", "LR P", "LR R", "LR F1", "SVM P", "SVM R", "SVM F1", "ANN P", "ANN R", "ANN F1"],["+BoW", "0.93", "0.91", "0.92", "0.94", "0.92", "0.93", "0.91", "0.91", "0.91"],["+BoC (Wiki-PubMed-PMC)", "0.94", "0.92", "0.93", "0.94", "0.92", "0.93", "0.91", "0.91", "0.91"],["+BoC (GloVe)", "0.93", "0.92", "0.92", "0.94", "0.92", "0.93", "0.91", "0.91", "0.91"],["+ASM", "0.90", "0.85", "0.88", "0.90", "0.86", "0.88", "0.89", "0.89", "0.89"],["+Sentence Embeddings(SEs)", "0.89", "0.89", "0.89", "0.90", "0.86", "0.88", "0.88", "0.88", "0.88"],["+BoC(Wiki-PubMed-PMC)+SEs", "0.92", "0.92", "0.92", "0.94", "0.92", "0.93", "0.91", "0.91", "0.91"]]
------
'''
Caption: Towards Quantifying the Distance between Opinions Table 5: We compare the quality of variants of Opinion Distance measures on opinion clustering task with ARI.
Table:
||  | Difference Function | Seanad Abolition | Video Games | Pornography ||
|| OD-parse | Absolute | 0.01 | -0.01 | 0.07 ||
|| OD-parse | JS div. | 0.01 | -0.01 | -0.01 ||
|| OD-parse | EMD | 0.07 | 0.01 | -0.01 ||
|| OD | Absolute | 0.54 | 0.56 | 0.41 ||
|| OD | JS div. | 0.07 | -0.01 | -0.02 ||
|| OD | EMD | 0.26 | -0.01 | 0.01 ||
|| OD (no polarity shifters) | Absolute | 0.23 | 0.08 | 0.04 ||
|| OD (no polarity shifters) | JS div. | 0.09 | -0.01 | -0.02 ||
|| OD (no polarity shifters) | EMD | 0.10 | 0.01 | -0.01 ||

Question: Is it true that OD significantly outperforms OD-parse: We observe that compared to OD-parse, OD is much more accurate?
'''

table_data = [["", "Difference Function", "Seanad Abolition", "Video Games", "Pornography"],["OD-parse", "Absolute", "0.01", "-0.01", "0.07"],["OD-parse", "JS div.", "0.01", "-0.01", "-0.01"],["OD-parse", "EMD", "0.07", "0.01", "-0.01"],["OD", "Absolute", "0.54", "0.56", "0.41"],["OD", "JS div.", "0.07", "-0.01", "-0.02"],["OD", "EMD", "0.26", "-0.01", "0.01"],["OD (no polarity shifters)", "Absolute", "0.23", "0.08", "0.04"],["OD (no polarity shifters)", "JS div.", "0.09", "-0.01", "-0.02"],["OD (no polarity shifters)", "EMD", "0.10", "0.01", "-0.01"]]
------
'''
[[LINEARIZED_TABLE]]
'''