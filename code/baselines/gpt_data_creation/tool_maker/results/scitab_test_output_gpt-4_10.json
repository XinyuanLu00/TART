[
  {
    "id": "b5d5b9ea-69ce-4b98-99de-831145e49e2b",
    "question": "Is it true that However, EWC outperforms no-reg and L2 on News, not only reducing forgetting but giving 0.5 BLEU improvement over the baseline News model?",
    "answer": "yes",
    "table_formatter_output": "table_data = [[\"\", \"Training scheme\", \"News\", \"TED\", \"IT\"],[\"1\", \"News\", \"37.8\", \"25.3\", \"35.3\"],[\"2\", \"TED\", \"23.7\", \"24.1\", \"14.4\"],[\"3\", \"IT\", \"1.6\", \"1.8\", \"39.6\"],[\"4\", \"News and TED\", \"38.2\", \"25.5\", \"35.4\"],[\"5\", \"1 then TED, No-reg\", \"30.6\", \"27.0\", \"22.1\"],[\"6\", \"1 then TED, L2\", \"37.9\", \"26.7\", \"31.8\"],[\"7\", \"1 then TED, EWC\", \"38.3\", \"27.0\", \"33.1\"],[\"8\", \"5 then IT, No-reg\", \"8.0\", \"6.9\", \"56.3\"],[\"9\", \"6 then IT, L2\", \"32.3\", \"22.6\", \"56.9\"],[\"10\", \"7 then IT, EWC\", \"35.8\", \"24.6\", \"57.0\"]]",
    "tool_maker_output": "def average_score(table, row_index):\n    scores = [float(x) for x in table[row_index][2:]]\n    return sum(scores) / len(scores)\n\ndef solution(table_data):\n    max_avg_score = 0\n    best_scheme = \"\"\n    for i in range(1, len(table_data)):\n        avg_score = average_score(table_data, i)\n        if avg_score > max_avg_score:\n            max_avg_score = avg_score\n            best_scheme = table_data[i][1]\n    return best_scheme\n\nprint(solution(table_data))"
  },
  {
    "id": "d85b8a88-a37f-4803-a198-3a7032d6e695",
    "question": "Is it true that  The Logistic Regression model achieved the best results with a F1-score of 0.679 on the training dataset and a F1-score of 0.572 on the test dataset?",
    "answer": "no",
    "table_formatter_output": "table_data = [[\"Model\", \"F1 (train)\", \"F1 (test)\"],[\"Multinomial Naive Bayes (using Count Vectorizer)\", \"0.641\", \"0.517\"],[\"Logistic Regression (using Count Vectorizer)\", \"0.679\", \"0.572\"],[\"SVM (Linear Kernel) (using TfIdf Vectorizer)\", \"0.695\", \"0.576\"],[\"LSTM (128 LSTM Units)\", \"0.731\", \"0.591\"],[\"Provided Baseline\", \"0.720\", \"0.267\"],[\"ULMFit*\", \"0.861\", \"0.701\"]]",
    "tool_maker_output": "def solution(table_data):\n    max_f1 = 0\n    best_model = \"\"\n    for row in table_data[1:]:\n        if float(row[2]) > max_f1:\n            max_f1 = float(row[2])\n            best_model = row[0]\n    return best_model\n\nprint(solution(table_data))"
  },
  {
    "id": "773f8b3d-676b-44d0-b830-93b964c3976c",
    "question": "Is it true that We gain further improvement by adding monolingual data and get an even higher accuracy of 75.5%, which is 10.1 points higher than the best language model?",
    "answer": "yes",
    "table_formatter_output": "table_data = [[\"\", \"dev perp ↓\", \"dev acc ↑\", \"dev wer ↓\", \"test perp ↓\", \"test acc ↑\", \"test wer ↓\"],[\"Spanish-only-LM\", \"329.68\", \"26.6\", \"30.47\", \"322.26\", \"25.1\", \"29.62\"],[\"English-only-LM\", \"320.92\", \"29.3\", \"32.02\", \"314.04\", \"30.3\", \"32.51\"],[\"All:CS-last-LM\", \"76.64\", \"47.8\", \"14.56\", \"76.97\", \"49.2\", \"14.13\"],[\"All:Shuffled-LM\", \"68.00\", \"51.8\", \"13.64\", \"68.72\", \"51.4\", \"13.89\"],[\"CS-only-LM\", \"43.20\", \"60.7\", \"12.60\", \"43.42\", \"57.9\", \"12.18\"],[\"CS-only+vocab-LM\", \"45.61\", \"61.0\", \"12.56\", \"45.79\", \"58.8\", \"12.49\"],[\"Fine-Tuned-LM\", \"39.76\", \"66.9\", \"10.71\", \"40.11\", \"65.4\", \"10.17\"],[\"CS-only-disc\", \"–\", \"72.0\", \"6.35\", \"–\", \"70.5\", \"6.70\"],[\"Fine-Tuned-disc\", \"–\", \"74.2\", \"5.85\", \"–\", \"75.5\", \"5.59\"]]",
    "tool_maker_output": "def solution(table_data):\n    min_perp = float('inf')\n    min_model = \"\"\n    for row in table_data[1:]:\n        if row[4] != \"–\":\n            perp = float(row[4])\n            if perp < min_perp:\n                min_perp = perp\n                min_model = row[0]\n    return min_model\n\nprint(solution(table_data))"
  },
  {
    "id": "5e806a3c-f8ff-469f-9d27-e6fc37a34a3d",
    "question": "Is it true that Our joint model outperforms all the base  lines with a gap of 10.5 CoNLL F1 points from the last published results (KCP), while surpassing our strong lemma baseline by 3 points?",
    "answer": "yes",
    "table_formatter_output": "table_data = [[\"Model\", \"R\", \"MUC P\", \"F1\", \"R\", \"B3 P\", \"F1\", \"R\", \"CEAF- e P\", \"F1\", \"CoNLL F1\"],[\"Baselines\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"],[\"Cluster+Lemma\", \"76.5\", \"79.9\", \"78.1\", \"71.7\", \"85\", \"77.8\", \"75.5\", \"71.7\", \"73.6\", \"76.5\"],[\"CV Cybulska and Vossen ( 2015a )\", \"71\", \"75\", \"73\", \"71\", \"78\", \"74\", \"-\", \"-\", \"64\", \"73\"],[\"KCP Kenyon-Dean et al. ( 2018 )\", \"67\", \"71\", \"69\", \"71\", \"67\", \"69\", \"71\", \"67\", \"69\", \"69\"],[\"Cluster+KCP\", \"68.4\", \"79.3\", \"73.4\", \"67.2\", \"87.2\", \"75.9\", \"77.4\", \"66.4\", \"71.5\", \"73.6\"],[\"Model Variants\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"],[\"Disjoint\", \"75.5\", \"83.6\", \"79.4\", \"75.4\", \"86\", \"80.4\", \"80.3\", \"71.9\", \"75.9\", \"78.5\"],[\"Joint\", \"77.6\", \"84.5\", \"80.9\", \"76.1\", \"85.1\", \"80.3\", \"81\", \"73.8\", \"77.3\", \"79.5\"]]",
    "tool_maker_output": "def highest_f1_score(table):\n    max_f1 = 0\n    max_model = \"\"\n    for row in table[2:]:\n        if row[10] != \"\":\n            f1_score = float(row[10])\n            if f1_score > max_f1:\n                max_f1 = f1_score\n                max_model = row[0]\n    return max_model\n\nprint(highest_f1_score(table_data))"
  },
  {
    "id": "cf78ecf8-180e-4067-9f5f-5091c236de7d",
    "question": "Is it true that Interestingly, the size and type of whitelist have a significant effect on performance, indicating that all the whitelists do not contain responses appropriate to a variety of conversational contexts?",
    "answer": "no",
    "table_formatter_output": "table_data = [[\"Whitelist\", \"Great\", \"Good\", \"Bad\", \"Accept\"],[\"Freq. 1K\", \"54%\", \"26%\", \"20%\", \"80%\"],[\"Cluster. 1K\", \"55%\", \"21%\", \"23%\", \"77%\"],[\"Freq. 10K\", \"56%\", \"24%\", \"21%\", \"80%\"],[\"Cluster. 10K\", \"57%\", \"23%\", \"20%\", \"80%\"],[\"Real response\", \"60%\", \"24%\", \"16%\", \"84%\"]]",
    "tool_maker_output": "def get_accept_rate(table, method):\n    for row in table:\n        if row[0] == method:\n            return float(row[-1].strip('%'))\n    return 0\n\ndef solution(table_data):\n    methods = [row[0] for row in table_data[1:]]\n    accept_rates = [get_accept_rate(table_data, method) for method in methods]\n    max_accept_rate = max(accept_rates)\n    real_response_rate = get_accept_rate(table_data, \"Real response\")\n    answer = real_response_rate == max_accept_rate\n    return answer\n\nprint(solution(table_data))"
  },
  {
    "id": "3f8320d5-deeb-473d-ba46-1fead5ed6bde",
    "question": "Is it true that We find that the effect of syntactic structure is consistent across the different relation types?",
    "answer": "no",
    "table_formatter_output": "table_data = [[\"Relation\", \"best F1 (in 5-fold) without sdp\", \"best F1 (in 5-fold) with sdp\", \"Diff.\"],[\"USAGE\", \"60.34\", \"80.24\", \"+ 19.90\"],[\"MODEL-FEATURE\", \"48.89\", \"70.00\", \"+ 21.11\"],[\"PART_WHOLE\", \"29.51\", \"70.27\", \"+40.76\"],[\"TOPIC\", \"45.80\", \"91.26\", \"+45.46\"],[\"RESULT\", \"54.35\", \"81.58\", \"+27.23\"],[\"COMPARE\", \"20.00\", \"61.82\", \"+ 41.82\"],[\"macro-averaged\", \"50.10\", \"76.10\", \"+26.00\"]]",
    "tool_maker_output": "def solution(table_data):\n    for row in table_data[1:]:\n        without_sdp = float(row[1])\n        with_sdp = float(row[2])\n        if without_sdp >= with_sdp:\n            return False\n    return True\n\nprint(solution(table_data))"
  },
  {
    "id": "a5751137-2fe5-4016-8932-c418dc82cae4",
    "question": "Is it true that  In addition, the presence of verbs in past participle (VBN) is the most distinctive part-of-speech pattern of complaints?",
    "answer": "yes",
    "table_formatter_output": "table_data = [[\"Complaints Feature\", \"Complaints r\", \"Not Complaints Feature\", \"Not Complaints r\"],[\"Unigrams\", \"Unigrams\", \"Unigrams\", \"Unigrams\"],[\"not\", \".154\", \"[URL]\", \".150\"],[\"my\", \".131\", \"!\", \".082\"],[\"working\", \".124\", \"he\", \".069\"],[\"still\", \".123\", \"thank\", \".067\"],[\"on\", \".119\", \",\", \".064\"],[\"can’t\", \".113\", \"love\", \".064\"],[\"service\", \".112\", \"lol\", \".061\"],[\"customer\", \".109\", \"you\", \".060\"],[\"why\", \".108\", \"great\", \".058\"],[\"website\", \".107\", \"win\", \".058\"],[\"no\", \".104\", \"’\", \".058\"],[\"?\", \".098\", \"she\", \".054\"],[\"fix\", \".093\", \":\", \".053\"],[\"won’t\", \".092\", \"that\", \".053\"],[\"been\", \".090\", \"more\", \".052\"],[\"issue\", \".089\", \"it\", \".052\"],[\"days\", \".088\", \"would\", \".051\"],[\"error\", \".087\", \"him\", \".047\"],[\"is\", \".084\", \"life\", \".046\"],[\"charged\", \".083\", \"good\", \".046\"],[\"POS (Unigrams and Bigrams)\", \"POS (Unigrams and Bigrams)\", \"POS (Unigrams and Bigrams)\", \"POS (Unigrams and Bigrams)\"],[\"VBN\", \".141\", \"UH\", \".104\"],[\"$\", \".118\", \"NNP\", \".098\"],[\"VBZ\", \".114\", \"PRP\", \".076\"],[\"NN_VBZ\", \".114\", \"HT\", \".076\"],[\"PRP$\", \".107\", \"PRP_.\", \".076\"],[\"PRP$_NN\", \".105\", \"PRP_RB\", \".067\"],[\"VBG\", \".093\", \"NNP_NNP\", \".062\"],[\"CD\", \".092\", \"VBP_PRP\", \".054\"],[\"WRB_VBZ\", \".084\", \"JJ\", \".053\"],[\"VBZ_VBN\", \".084\", \"DT_JJ\", \".051\"]]",
    "tool_maker_output": "def top_features(table, column_index):\n    top_5 = []\n    for row in table[1:]:\n        top_5.append((row[0], float(row[column_index])))\n    top_5.sort(key=lambda x: x[1], reverse=True)\n    return [x[0] for x in top_5[:5]]\n\ndef solution(table_data):\n    complaints_features = top_features(table_data, 1)\n    not_complaints_features = top_features(table_data, 3)\n    return complaints_features, not_complaints_features\n\ncomplaints_features, not_complaints_features = solution(table_data)\nprint(\"Top 5 features for complaints: \", complaints_features)\nprint(\"Top 5 features for not complaints: \", not_complaints_features)"
  },
  {
    "id": "813352e2-948e-4c73-b239-4420a1634970",
    "question": "Is it true that The difference is most prevalent in KP20k, the largest of the four datasets, where our GAN model (at 0.85) is only marginally better than both the other baseline models?",
    "answer": "no",
    "table_formatter_output": "table_data = [[\"Model\", \"Inspec\", \"Krapivin\", \"NUS\", \"KP20k\"],[\"Catseq\", \"0.87803\", \"0.781\", \"0.82118\", \"0.804\"],[\"Catseq-RL\", \"0.8602\", \"0.786\", \"0.83\", \"0.809\"],[\"GAN\", \"0.891\", \"0.771\", \"0.853\", \"0.85\"]]",
    "tool_maker_output": "def average_performance(table, model):\n    scores = []\n    for row in table:\n        if row[0] == model:\n            scores.extend([float(x) for x in row[1:]])\n    return sum(scores) / len(scores)\n\ndef solution(table_data):\n    catseq_score = average_performance(table_data[1:], \"Catseq\")\n    catseq_rl_score = average_performance(table_data[1:], \"Catseq-RL\")\n    gan_score = average_performance(table_data[1:], \"GAN\")\n    answer = gan_score > catseq_score and gan_score > catseq_rl_score\n    return answer\n\nprint(solution(table_data))"
  },
  {
    "id": "d2534ed4-c340-4211-8610-924f9fb9c445",
    "question": "Is it true that FME outperforms the AME model, confirming the importance of word embeddings adaptation?",
    "answer": "no",
    "table_formatter_output": "table_data = [[\"\", \"EN → DE R@1\", \"EN → DE R@5\", \"EN → DE R@10\", \"DE → EN R@1\", \"DE → EN R@5\", \"DE → EN R@10\"],[\"FME\", \"51.4\", \"76.4\", \"84.5\", \"46.9\", \"71.2\", \"79.1\"],[\"AME\", \"51.7\", \"76.7\", \"85.1\", \"49.1\", \"72.6\", \"80.5\"]]",
    "tool_maker_output": "def average_scores(table, method):\n    scores = []\n    for row in table:\n        if row[0] == method:\n            scores.extend([float(x) for x in row[1:]])\n    return sum(scores) / len(scores)\n\ndef solution(table_data):\n    fme_score = average_scores(table_data[1:], \"FME\")\n    ame_score = average_scores(table_data[1:], \"AME\")\n    answer = ame_score > fme_score\n    return answer\n\nprint(solution(table_data))"
  },
  {
    "id": "bf52da4c-3af3-4cc3-9e6d-19e0744ef2fe",
    "question": "Is it true that Patt model could not generate relations for all terms because terms must to be in a pattern in order to have their taxonomic relation identified?",
    "answer": "yes",
    "table_formatter_output": "table_data = [[\"Corpus\", \"Metric\", \"Patt\", \"DSim\", \"SLQS\", \"TF\", \"DF\", \"DocSub\", \"HClust\"],[\"Europarl\", \"TotalTerms:\", \"957\", \"1,000\", \"1,000\", \"1,000\", \"1,000\", \"836\", \"1,000\"],[\"Europarl\", \"TotalRoots:\", \"44\", \"1\", \"1\", \"1\", \"1\", \"43\", \"1\"],[\"Europarl\", \"NumberRels:\", \"1,588\", \"1,025\", \"1,028\", \"1,185\", \"1,103\", \"1,184\", \"999\"],[\"Europarl\", \"MaxDepth:\", \"21\", \"921\", \"901\", \"788\", \"835\", \"8\", \"15\"],[\"Europarl\", \"MinDepth:\", \"1\", \"921\", \"901\", \"788\", \"835\", \"1\", \"1\"],[\"Europarl\", \"AvgDepth:\", \"11.82\", \"921\", \"901\", \"788\", \"835\", \"3.05\", \"8.46\"],[\"Europarl\", \"DepthCohesion:\", \"1.78\", \"1\", \"1\", \"1\", \"1\", \"2.62\", \"1.77\"],[\"Europarl\", \"MaxWidth:\", \"20\", \"2\", \"3\", \"4\", \"3\", \"88\", \"41\"],[\"Europarl\", \"MinWidth:\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\"],[\"Europarl\", \"AvgWidth:\", \"1.99\", \"1.03\", \"1.03\", \"1.19\", \"1.10\", \"4.20\", \"2.38\"],[\"TED Talks\", \"TotalTerms:\", \"476\", \"1,000\", \"1,000\", \"1,000\", \"1,000\", \"1,000\", \"1,000\"],[\"TED Talks\", \"TotalRoots:\", \"164\", \"2\", \"1\", \"1\", \"1\", \"1\", \"1\"],[\"TED Talks\", \"NumberRels:\", \"521\", \"1,029\", \"1,331\", \"3,025\", \"3,438\", \"3,802\", \"1,009\"],[\"TED Talks\", \"MaxDepth:\", \"16\", \"915\", \"658\", \"454\", \"395\", \"118\", \"12\"],[\"TED Talks\", \"MinDepth:\", \"1\", \"913\", \"658\", \"454\", \"395\", \"110\", \"1\"],[\"TED Talks\", \"AvgDepth:\", \"5.82\", \"914\", \"658\", \"454\", \"395\", \"112.24\", \"5.95\"],[\"TED Talks\", \"DepthCohesion:\", \"2.75\", \"1\", \"1\", \"1\", \"1\", \"1.05\", \"2.02\"],[\"TED Talks\", \"MaxWidth:\", \"25\", \"2\", \"77\", \"13\", \"12\", \"66\", \"98\"],[\"TED Talks\", \"MinWidth:\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\"],[\"TED Talks\", \"AvgWidth:\", \"1.83\", \"1.03\", \"1.36\", \"3.03\", \"3.44\", \"6.64\", \"2.35\"]]",
    "tool_maker_output": "def average_depth(table, corpus):\n    depths = []\n    for row in table:\n        if row[0] == corpus and row[1] == \"AvgDepth:\":\n            depths = [float(x.replace(',', '')) for x in row[2:]]\n    return depths.index(max(depths)) + 2\n\ndef solution(table_data):\n    methods = table_data[0][2:]\n    index = average_depth(table_data[1:], \"Europarl\")\n    answer = methods[index]\n    return answer\n\nprint(solution(table_data))"
  }
]